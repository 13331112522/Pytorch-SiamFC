2018-09-17 17:46:30,161:INFO: ----Starting train script in mode: train----
2018-09-17 17:46:30,161:INFO: Loading datasets...
2018-09-17 17:46:43,323:INFO: ----Starting train script in mode: train----
2018-09-17 17:46:43,323:INFO: Loading datasets...
2018-09-17 17:48:09,856:INFO: ----Starting train script in mode: train----
2018-09-17 17:48:09,857:INFO: Loading datasets...
2018-09-17 17:48:35,665:INFO: ----Starting train script in mode: train----
2018-09-17 17:48:35,665:INFO: Loading datasets...
2018-09-17 17:59:14,076:INFO: ----Starting train script in mode: train----
2018-09-17 17:59:14,076:INFO: Loading datasets...
2018-09-17 17:59:21,922:INFO: ----Starting train script in mode: train----
2018-09-17 17:59:21,922:INFO: Loading datasets...
2018-09-17 18:00:40,772:INFO: ----Starting train script in mode: train----
2018-09-17 18:00:40,772:INFO: Loading datasets...
2018-09-17 18:01:05,609:INFO: ----Starting train script in mode: train----
2018-09-17 18:01:05,609:INFO: Loading datasets...
2018-09-17 18:01:30,985:INFO: ----Starting train script in mode: train----
2018-09-17 18:01:30,986:INFO: Loading datasets...
2018-09-17 18:01:48,849:INFO: ----Starting train script in mode: train----
2018-09-17 18:01:48,849:INFO: Loading datasets...
2018-09-17 18:02:51,951:INFO: ----Starting train script in mode: train----
2018-09-17 18:02:51,951:INFO: Loading datasets...
2018-09-17 18:04:21,792:INFO: ----Starting train script in mode: train----
2018-09-17 18:04:21,792:INFO: Loading datasets...
2018-09-17 18:05:10,023:INFO: ----Starting train script in mode: train----
2018-09-17 18:05:10,023:INFO: Loading datasets...
2018-09-17 18:06:03,087:INFO: ----Starting train script in mode: train----
2018-09-17 18:06:03,087:INFO: Loading datasets...
2018-09-17 18:06:08,658:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-17 18:06:10,976:INFO: Done
2018-09-17 18:06:10,976:INFO: Setup time: 0h0m7.89s
2018-09-17 18:06:10,977:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-17 18:06:10,977:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-17 18:06:10,977:INFO: Starting training for 10 epoch(s)
2018-09-17 18:06:10,978:INFO: Pretraining evaluation...
2018-09-17 18:06:10,978:INFO: Validation on val set
2018-09-17 18:06:11,350:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 156, in main
    metrics, params, exp_dir, args.restore_file)
  File "train.py", line 309, in train_and_evaluate
    val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)
  File "train.py", line 375, in evaluate
    for i, (ref_img_batch, search_batch, labels_batch) in enumerate(dataloader):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 339, in __next__
    return self._process_next_batch(batch)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 360, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
AttributeError: Traceback (most recent call last):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 368, in __getitem__
    return self.preprocess_sample(first_idx, second_idx, list_idx)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 265, in preprocess_sample
    if self.single_label:
AttributeError: 'ImageNetVID_val' object has no attribute 'single_label'

2018-09-17 18:06:11,352:INFO: === Execution Terminated with error ===
2018-09-17 18:08:10,617:INFO: ----Starting train script in mode: train----
2018-09-17 18:08:10,618:INFO: Loading datasets...
2018-09-17 18:08:14,828:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-17 18:08:16,565:INFO: Done
2018-09-17 18:08:16,565:INFO: Setup time: 0h0m5.95s
2018-09-17 18:08:16,566:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-17 18:08:16,566:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-17 18:08:16,566:INFO: Starting training for 10 epoch(s)
2018-09-17 18:08:16,566:INFO: Pretraining evaluation...
2018-09-17 18:08:16,567:INFO: Validation on val set
2018-09-17 18:08:16,706:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 156, in main
    metrics, params, exp_dir, args.restore_file)
  File "train.py", line 309, in train_and_evaluate
    val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)
  File "train.py", line 375, in evaluate
    for i, (ref_img_batch, search_batch, labels_batch) in enumerate(dataloader):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 339, in __next__
    return self._process_next_batch(batch)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 360, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
ValueError: Traceback (most recent call last):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 365, in __getitem__
    return self.preprocess_sample(first_idx, second_idx, list_idx)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 265, in preprocess_sample
    label = self.label or self.label_fcn(self.final_size, self.pos_thr, self.neg_thr,
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

2018-09-17 18:08:16,707:INFO: === Execution Terminated with error ===
2018-09-17 18:08:52,418:INFO: ----Starting train script in mode: train----
2018-09-17 18:08:52,418:INFO: Loading datasets...
2018-09-17 18:08:57,307:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-17 18:08:58,919:INFO: Done
2018-09-17 18:08:58,920:INFO: Setup time: 0h0m6.50s
2018-09-17 18:08:58,920:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-17 18:08:58,921:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-17 18:08:58,921:INFO: Starting training for 10 epoch(s)
2018-09-17 18:08:58,921:INFO: Pretraining evaluation...
2018-09-17 18:08:58,922:INFO: Validation on val set
2018-09-17 18:09:02,211:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 156, in main
    metrics, params, exp_dir, args.restore_file)
  File "train.py", line 309, in train_and_evaluate
    val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)
  File "train.py", line 395, in evaluate
    output_batch = model(ref_img_batch, search_batch)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 98, in forward
    embedding_reference = self.embedding_net(x1)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py", line 46, in forward
    return F.threshold(input, self.threshold, self.value, self.inplace)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 647, in threshold
    return torch._C._nn.threshold(input, threshold, value)
RuntimeError: CUDA error: out of memory
2018-09-17 18:09:02,218:INFO: === Execution Terminated with error ===
2018-09-17 18:11:28,960:INFO: ----Starting train script in mode: train----
2018-09-17 18:11:28,960:INFO: Loading datasets...
2018-09-17 18:11:32,535:INFO: ----Starting train script in mode: train----
2018-09-17 18:11:32,536:INFO: Loading datasets...
2018-09-17 18:11:38,670:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-17 18:11:41,191:INFO: Done
2018-09-17 18:11:41,192:INFO: Setup time: 0h0m8.66s
2018-09-17 18:11:41,192:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-17 18:11:41,193:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-17 18:11:41,193:INFO: Starting training for 10 epoch(s)
2018-09-17 18:11:41,193:INFO: Pretraining evaluation...
2018-09-17 18:11:41,193:INFO: Epoch 1/10
2018-09-17 18:11:41,194:INFO: Training on train set
2018-09-17 18:11:44,333:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 156, in main
    metrics, params, exp_dir, args.restore_file)
  File "train.py", line 316, in train_and_evaluate
    train(model, optimizer, loss_fn, train_dataloader, metrics, params)
  File "train.py", line 236, in train
    output_batch = model(ref_img_batch, search_batch)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 99, in forward
    embedding_search = self.embedding_net(x2)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py", line 46, in forward
    return F.threshold(input, self.threshold, self.value, self.inplace)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 647, in threshold
    return torch._C._nn.threshold(input, threshold, value)
RuntimeError: CUDA error: out of memory
2018-09-17 18:11:44,341:INFO: === Execution Terminated with error ===
2018-09-18 15:08:45,350:INFO: ----Starting train script in mode: train----
2018-09-18 15:08:45,351:INFO: Loading datasets...
2018-09-18 15:12:49,722:INFO: ----Starting train script in mode: train----
2018-09-18 15:12:49,722:INFO: Loading datasets...
2018-09-18 15:14:13,616:INFO: ----Starting train script in mode: train----
2018-09-18 15:14:13,616:INFO: Loading datasets...
2018-09-18 15:14:34,976:INFO: ----Starting train script in mode: train----
2018-09-18 15:14:34,977:INFO: Loading datasets...
2018-09-18 15:14:58,534:INFO: ----Starting train script in mode: train----
2018-09-18 15:14:58,534:INFO: Loading datasets...
2018-09-18 15:15:16,190:INFO: ----Starting train script in mode: train----
2018-09-18 15:15:16,190:INFO: Loading datasets...
2018-09-18 15:16:45,875:INFO: ----Starting train script in mode: train----
2018-09-18 15:16:45,875:INFO: Loading datasets...
2018-09-18 15:17:38,864:INFO: ----Starting train script in mode: train----
2018-09-18 15:17:38,865:INFO: Loading datasets...
2018-09-18 15:17:45,599:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:17:45,601:INFO: Done
2018-09-18 15:17:45,601:INFO: Setup time: 0h0m6.74s
2018-09-18 15:17:45,601:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:17:45,601:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:17:45,601:INFO: Starting training for 10 epoch(s)
2018-09-18 15:17:45,601:INFO: Pretraining evaluation...
2018-09-18 15:17:45,601:INFO: Validation on val set
2018-09-18 15:17:50,741:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 455, in evaluate
    seq_name = dataloader.dataset.get_seq_name(seq)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 186, in get_seq_name
    return self.frames[seq_idx][0].split(os.sep)[-2]
IndexError: list index out of range
2018-09-18 15:17:50,747:INFO: === Execution Terminated with error ===
2018-09-18 15:18:20,862:INFO: ----Starting train script in mode: train----
2018-09-18 15:18:20,862:INFO: Loading datasets...
2018-09-18 15:18:27,814:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:18:27,820:INFO: Done
2018-09-18 15:18:27,821:INFO: Setup time: 0h0m6.96s
2018-09-18 15:18:27,821:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:18:27,821:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:18:27,821:INFO: Starting training for 10 epoch(s)
2018-09-18 15:18:27,821:INFO: Pretraining evaluation...
2018-09-18 15:18:27,821:INFO: Validation on val set
2018-09-18 15:18:30,301:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 455, in evaluate
    seq_name = dataloader.dataset.get_seq_name(seq)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 186, in get_seq_name
    print(self.frames[seq_idx])
IndexError: list index out of range
2018-09-18 15:18:30,306:INFO: === Execution Terminated with error ===
2018-09-18 15:18:44,174:INFO: ----Starting train script in mode: train----
2018-09-18 15:18:44,174:INFO: Loading datasets...
2018-09-18 15:18:50,726:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:18:50,728:INFO: Done
2018-09-18 15:18:50,728:INFO: Setup time: 0h0m6.55s
2018-09-18 15:18:50,729:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:18:50,729:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:18:50,729:INFO: Starting training for 10 epoch(s)
2018-09-18 15:18:50,729:INFO: Pretraining evaluation...
2018-09-18 15:18:50,729:INFO: Validation on val set
2018-09-18 15:18:53,308:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 455, in evaluate
    seq_name = dataloader.dataset.get_seq_name(seq)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 187, in get_seq_name
    return self.frames[seq_idx][0].split(os.sep)[-2]
IndexError: list index out of range
2018-09-18 15:18:53,314:INFO: === Execution Terminated with error ===
2018-09-18 15:19:42,745:INFO: ----Starting train script in mode: train----
2018-09-18 15:19:42,745:INFO: Loading datasets...
2018-09-18 15:19:49,665:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:19:49,671:INFO: Done
2018-09-18 15:19:49,671:INFO: Setup time: 0h0m6.93s
2018-09-18 15:19:49,672:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:19:49,672:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:19:49,672:INFO: Starting training for 10 epoch(s)
2018-09-18 15:19:49,672:INFO: Pretraining evaluation...
2018-09-18 15:19:49,672:INFO: Validation on val set
2018-09-18 15:19:52,092:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 455, in evaluate
    seq_name = dataloader.dataset.get_seq_name(seq)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 187, in get_seq_name
    return self.frames[seq_idx][0].split(os.sep)[-2]
IndexError: list index out of range
2018-09-18 15:19:52,095:INFO: === Execution Terminated with error ===
2018-09-18 15:23:44,715:INFO: ----Starting train script in mode: train----
2018-09-18 15:23:44,715:INFO: Loading datasets...
2018-09-18 15:23:50,573:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:23:50,575:INFO: Done
2018-09-18 15:23:50,575:INFO: Setup time: 0h0m5.86s
2018-09-18 15:23:50,575:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:23:50,575:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:23:50,575:INFO: Starting training for 10 epoch(s)
2018-09-18 15:23:50,575:INFO: Pretraining evaluation...
2018-09-18 15:23:50,576:INFO: Validation on val set
2018-09-18 15:23:52,945:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 456, in evaluate
    seq_name = dataloader.dataset.get_seq_name(seq)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 186, in get_seq_name
    return self.frames[seq_idx][0].split(os.sep)[-2]
IndexError: list index out of range
2018-09-18 15:23:52,949:INFO: === Execution Terminated with error ===
2018-09-18 15:24:43,862:INFO: ----Starting train script in mode: train----
2018-09-18 15:24:43,862:INFO: Loading datasets...
2018-09-18 15:24:50,264:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:24:50,266:INFO: Done
2018-09-18 15:24:50,266:INFO: Setup time: 0h0m6.40s
2018-09-18 15:24:50,266:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:24:50,266:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:24:50,266:INFO: Starting training for 10 epoch(s)
2018-09-18 15:24:50,266:INFO: Pretraining evaluation...
2018-09-18 15:24:50,266:INFO: Validation on val set
2018-09-18 15:24:53,448:INFO: Saving embeddings for summary 0
2018-09-18 15:24:54,739:INFO: Saving embeddings for summary 1
2018-09-18 15:24:56,085:INFO: Saving embeddings for summary 2
2018-09-18 15:24:57,347:INFO: Saving embeddings for summary 3
2018-09-18 15:24:58,691:INFO: Saving embeddings for summary 4
2018-09-18 15:24:59,351:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 434, in evaluate
    embed_ref = model.get_embedding(ref_img_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 105, in get_embedding
    return self.embedding_net(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/pooling.py", line 138, in forward
    self.return_indices)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 398, in max_pool2d
    ret = torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA error: out of memory
2018-09-18 15:24:59,355:INFO: === Execution Terminated with error ===
2018-09-18 15:28:04,064:INFO: ----Starting train script in mode: train----
2018-09-18 15:28:04,064:INFO: Loading datasets...
2018-09-18 15:28:09,815:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:28:09,817:INFO: Done
2018-09-18 15:28:09,817:INFO: Setup time: 0h0m5.75s
2018-09-18 15:28:09,817:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (92). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:28:09,817:INFO: Epoch sizes: 92 in train and 92 in eval
2018-09-18 15:28:09,817:INFO: Starting training for 10 epoch(s)
2018-09-18 15:28:09,817:INFO: Pretraining evaluation...
2018-09-18 15:28:09,817:INFO: Validation on val set
2018-09-18 15:28:12,014:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 467, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 15:28:12,015:INFO: === Execution Terminated with error ===
2018-09-18 15:52:59,221:INFO: ----Starting train script in mode: train----
2018-09-18 15:52:59,221:INFO: Loading datasets...
2018-09-18 15:53:24,185:INFO: ----Starting train script in mode: train----
2018-09-18 15:53:24,185:INFO: Loading datasets...
2018-09-18 15:53:31,218:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:53:34,015:INFO: Done
2018-09-18 15:53:34,015:INFO: Setup time: 0h0m9.83s
2018-09-18 15:53:34,015:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:53:34,015:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 15:53:34,015:INFO: Starting training for 10 epoch(s)
2018-09-18 15:53:34,015:INFO: Pretraining evaluation...
2018-09-18 15:53:34,016:INFO: Validation on val set
2018-09-18 15:53:34,074:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 414, in evaluate
    for i, sample in enumerate(dataloader):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 339, in __next__
    return self._process_next_batch(batch)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 360, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
AttributeError: Traceback (most recent call last):
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 113, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/datasets.py", line 494, in __getitem__
    list_idx, first_idx, second_idx = self.list_pairs[idx]
AttributeError: 'ImageNetVID_val' object has no attribute 'list_pairs'

2018-09-18 15:53:34,075:INFO: === Execution Terminated with error ===
2018-09-18 15:54:07,870:INFO: ----Starting train script in mode: train----
2018-09-18 15:54:07,870:INFO: Loading datasets...
2018-09-18 15:54:13,674:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:54:16,088:INFO: Done
2018-09-18 15:54:16,088:INFO: Setup time: 0h0m8.22s
2018-09-18 15:54:16,089:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:54:16,089:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 15:54:16,089:INFO: Starting training for 10 epoch(s)
2018-09-18 15:54:16,089:INFO: Pretraining evaluation...
2018-09-18 15:54:16,089:INFO: Validation on val set
2018-09-18 15:54:19,542:INFO: Saving embeddings for summary 0
2018-09-18 15:54:20,797:INFO: Saving embeddings for summary 1
2018-09-18 15:54:22,176:INFO: Saving embeddings for summary 2
2018-09-18 15:54:23,550:INFO: Saving embeddings for summary 3
2018-09-18 15:54:24,878:INFO: Saving embeddings for summary 4
2018-09-18 15:54:25,516:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 434, in evaluate
    embed_ref = model.get_embedding(ref_img_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 105, in get_embedding
    return self.embedding_net(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/pooling.py", line 138, in forward
    self.return_indices)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 398, in max_pool2d
    ret = torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA error: out of memory
2018-09-18 15:54:25,519:INFO: === Execution Terminated with error ===
2018-09-18 15:55:18,680:INFO: ----Starting train script in mode: train----
2018-09-18 15:55:18,680:INFO: Loading datasets...
2018-09-18 15:55:25,789:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:55:28,800:INFO: Done
2018-09-18 15:55:28,800:INFO: Setup time: 0h0m10.12s
2018-09-18 15:55:28,800:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:55:28,800:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 15:55:28,800:INFO: Starting training for 10 epoch(s)
2018-09-18 15:55:28,800:INFO: Pretraining evaluation...
2018-09-18 15:55:28,800:INFO: Validation on val set
2018-09-18 15:55:32,156:INFO: Saving embeddings for summary 0
2018-09-18 15:55:33,444:INFO: Saving embeddings for summary 1
2018-09-18 15:55:34,832:INFO: Saving embeddings for summary 2
2018-09-18 15:55:36,187:INFO: Saving embeddings for summary 3
2018-09-18 15:55:37,570:INFO: Saving embeddings for summary 4
2018-09-18 15:55:38,205:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 434, in evaluate
    embed_ref = model.get_embedding(ref_img_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 105, in get_embedding
    return self.embedding_net(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/pooling.py", line 138, in forward
    self.return_indices)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 398, in max_pool2d
    ret = torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA error: out of memory
2018-09-18 15:55:38,211:INFO: === Execution Terminated with error ===
2018-09-18 15:57:04,285:INFO: ----Starting train script in mode: train----
2018-09-18 15:57:04,285:INFO: Loading datasets...
2018-09-18 15:57:11,577:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:57:14,777:INFO: Done
2018-09-18 15:57:14,777:INFO: Setup time: 0h0m10.49s
2018-09-18 15:57:14,777:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:57:14,777:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 15:57:14,778:INFO: Starting training for 10 epoch(s)
2018-09-18 15:57:14,778:INFO: Pretraining evaluation...
2018-09-18 15:57:14,779:INFO: Validation on val set
2018-09-18 15:57:17,002:INFO: === User interrupted execution ===
2018-09-18 15:59:22,708:INFO: ----Starting train script in mode: train----
2018-09-18 15:59:22,709:INFO: Loading datasets...
2018-09-18 15:59:29,329:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 15:59:31,655:INFO: Done
2018-09-18 15:59:31,656:INFO: Setup time: 0h0m8.95s
2018-09-18 15:59:31,656:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 15:59:31,656:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 15:59:31,657:INFO: Starting training for 10 epoch(s)
2018-09-18 15:59:31,657:INFO: Pretraining evaluation...
2018-09-18 15:59:31,657:INFO: Validation on val set
2018-09-18 15:59:34,935:INFO: Saving embeddings for summary 0
2018-09-18 15:59:36,187:INFO: Saving embeddings for summary 1
2018-09-18 15:59:37,581:INFO: Saving embeddings for summary 2
2018-09-18 15:59:38,873:INFO: Saving embeddings for summary 3
2018-09-18 15:59:40,202:INFO: Saving embeddings for summary 4
2018-09-18 15:59:40,817:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 434, in evaluate
    embed_ref = model.get_embedding(ref_img_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 105, in get_embedding
    return self.embedding_net(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/models.py", line 50, in forward
    output = self.fully_conv(x)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/modules/pooling.py", line 138, in forward
    self.return_indices)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 398, in max_pool2d
    ret = torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: CUDA error: out of memory
2018-09-18 15:59:40,825:INFO: === Execution Terminated with error ===
2018-09-18 16:05:04,853:INFO: ----Starting train script in mode: train----
2018-09-18 16:05:04,853:INFO: Loading datasets...
2018-09-18 16:05:12,005:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 16:05:14,622:INFO: Done
2018-09-18 16:05:14,622:INFO: Setup time: 0h0m9.77s
2018-09-18 16:05:14,623:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 16:05:14,623:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 16:05:14,623:INFO: Starting training for 10 epoch(s)
2018-09-18 16:05:14,623:INFO: Pretraining evaluation...
2018-09-18 16:05:14,623:INFO: Validation on val set
2018-09-18 16:05:16,908:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 467, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 16:05:16,912:INFO: === Execution Terminated with error ===
2018-09-18 16:07:26,941:INFO: ----Starting train script in mode: train----
2018-09-18 16:07:26,941:INFO: Loading datasets...
2018-09-18 16:07:34,730:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 16:07:36,558:INFO: Done
2018-09-18 16:07:36,558:INFO: Setup time: 0h0m9.62s
2018-09-18 16:07:36,558:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 16:07:36,558:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 16:07:36,558:INFO: Starting training for 10 epoch(s)
2018-09-18 16:07:36,559:INFO: Pretraining evaluation...
2018-09-18 16:07:36,559:INFO: Validation on val set
2018-09-18 16:07:38,880:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 467, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 16:07:38,882:INFO: === Execution Terminated with error ===
2018-09-18 16:08:08,498:INFO: ----Starting train script in mode: train----
2018-09-18 16:08:08,498:INFO: Loading datasets...
2018-09-18 16:08:15,583:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 16:08:17,889:INFO: Done
2018-09-18 16:08:17,889:INFO: Setup time: 0h0m9.39s
2018-09-18 16:08:17,890:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 16:08:17,890:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 16:08:17,890:INFO: Starting training for 10 epoch(s)
2018-09-18 16:08:17,890:INFO: Pretraining evaluation...
2018-09-18 16:08:17,890:INFO: Validation on val set
2018-09-18 16:08:20,011:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 170, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 247, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 467, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 16:08:20,011:INFO: === Execution Terminated with error ===
2018-09-18 16:09:30,095:INFO: ----Starting train script in mode: train----
2018-09-18 16:09:30,095:INFO: Loading datasets...
2018-09-18 16:09:31,398:INFO: Validation dataset...
2018-09-18 16:09:36,690:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 16:09:36,690:INFO: Training dataset...
2018-09-18 16:09:38,912:INFO: Done
2018-09-18 16:09:38,912:INFO: Setup time: 0h0m8.82s
2018-09-18 16:09:38,913:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 16:09:38,913:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 16:09:38,913:INFO: Starting training for 10 epoch(s)
2018-09-18 16:09:38,913:INFO: Pretraining evaluation...
2018-09-18 16:09:38,913:INFO: Validation on val set
2018-09-18 16:09:40,813:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 176, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 253, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 473, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 16:09:40,813:INFO: === Execution Terminated with error ===
2018-09-18 16:10:46,765:INFO: ----Starting train script in mode: train----
2018-09-18 16:10:46,765:INFO: Loading datasets...
2018-09-18 16:10:48,015:INFO: Validation dataset...
2018-09-18 16:10:52,762:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 16:10:52,762:INFO: Training dataset...
2018-09-18 16:10:54,271:INFO: The user set train_epoch_size (50000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 16:10:54,272:INFO: Done
2018-09-18 16:10:54,272:INFO: Setup time: 0h0m7.51s
2018-09-18 16:10:54,272:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 16:10:54,272:INFO: Starting training for 10 epoch(s)
2018-09-18 16:10:54,272:INFO: Pretraining evaluation...
2018-09-18 16:10:54,273:INFO: Validation on val set
2018-09-18 16:10:55,824:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 177, in main
    metrics, params, exp_dir, args, summ_maker=summ_maker)
  File "train.py", line 254, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 474, in evaluate
    cmap='inferno')
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/summary_utils.py", line 156, in add_overlay
    final_imgs = alpha * embed + (1-alpha) * img_gray
RuntimeError: CUDA error: out of memory
2018-09-18 16:10:55,825:INFO: === Execution Terminated with error ===
2018-09-18 19:17:11,955:INFO: ----Starting train script in mode: train----
2018-09-18 19:17:11,955:INFO: Loading datasets...
2018-09-18 19:17:13,083:INFO: Validation dataset...
2018-09-18 19:17:18,420:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:17:18,420:INFO: Training dataset...
2018-09-18 19:17:20,556:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:17:20,557:INFO: Done
2018-09-18 19:17:20,557:INFO: Setup time: 0h0m8.60s
2018-09-18 19:17:20,557:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:17:20,557:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:17:20,558:INFO: Starting training for 1 epoch(s)
2018-09-18 19:17:20,558:INFO: Pretraining evaluation...
2018-09-18 19:17:20,558:INFO: Validation on val set
2018-09-18 19:17:22,623:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 193, in main
    args, summ_maker=summ_maker)
  File "train.py", line 271, in train_and_evaluate
    summ_maker=summ_maker)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 46, in decorate_no_grad
    return func(*args, **kwargs)
  File "train.py", line 445, in evaluate
    loss = loss_fn(output_batch, labels_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/losses.py", line 19, in BCELogit_Loss
    size_average=True)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 1727, in binary_cross_entropy_with_logits
    loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()
RuntimeError: TensorIterator expected type torch.cuda.DoubleTensor but got torch.cuda.FloatTensor[8, 1, 33, 33]
2018-09-18 19:17:22,629:INFO: === Execution Terminated with error ===
2018-09-18 19:18:46,362:INFO: ----Starting train script in mode: train----
2018-09-18 19:18:46,362:INFO: Loading datasets...
2018-09-18 19:18:47,733:INFO: Validation dataset...
2018-09-18 19:18:52,823:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:18:52,823:INFO: Training dataset...
2018-09-18 19:18:54,907:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:18:54,907:INFO: Done
2018-09-18 19:18:54,907:INFO: Setup time: 0h0m8.54s
2018-09-18 19:18:54,907:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:18:54,908:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:18:54,908:INFO: Starting training for 1 epoch(s)
2018-09-18 19:18:54,908:INFO: Pretraining evaluation...
2018-09-18 19:18:54,908:INFO: Validation on val set
2018-09-18 19:18:57,057:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 193, in main
    args, summ_maker=summ_maker)
  File "train.py", line 271, in train_and_evaluate
    summ_maker=summ_maker)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 46, in decorate_no_grad
    return func(*args, **kwargs)
  File "train.py", line 445, in evaluate
    loss = loss_fn(output_batch, labels_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/losses.py", line 21, in BCELogit_Loss
    size_average=True)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 1727, in binary_cross_entropy_with_logits
    loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()
RuntimeError: TensorIterator expected type torch.cuda.DoubleTensor but got torch.cuda.FloatTensor[8, 1, 33, 33]
2018-09-18 19:18:57,058:INFO: === Execution Terminated with error ===
2018-09-18 19:19:18,104:INFO: ----Starting train script in mode: train----
2018-09-18 19:19:18,104:INFO: Loading datasets...
2018-09-18 19:19:19,109:INFO: Validation dataset...
2018-09-18 19:19:24,934:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:19:24,934:INFO: Training dataset...
2018-09-18 19:19:27,315:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:19:27,316:INFO: Done
2018-09-18 19:19:27,316:INFO: Setup time: 0h0m9.21s
2018-09-18 19:19:27,316:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:19:27,316:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:19:27,316:INFO: Starting training for 1 epoch(s)
2018-09-18 19:19:27,316:INFO: Pretraining evaluation...
2018-09-18 19:19:27,317:INFO: Validation on val set
2018-09-18 19:19:28,932:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 193, in main
    args, summ_maker=summ_maker)
  File "train.py", line 271, in train_and_evaluate
    summ_maker=summ_maker)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/autograd/grad_mode.py", line 46, in decorate_no_grad
    return func(*args, **kwargs)
  File "train.py", line 445, in evaluate
    loss = loss_fn(output_batch, labels_batch)
  File "/home/cpinard/siamFC/DeepLearningTools/Tracking/siamfc-pytorch/training/losses.py", line 21, in BCELogit_Loss
    size_average=True)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py", line 1733, in binary_cross_entropy_with_logits
    loss = loss * weight
RuntimeError: TensorIterator expected type torch.cuda.DoubleTensor but got torch.cuda.FloatTensor[8, 1, 33, 33]
2018-09-18 19:19:28,933:INFO: === Execution Terminated with error ===
2018-09-18 19:21:14,842:INFO: ----Starting train script in mode: train----
2018-09-18 19:21:14,842:INFO: Loading datasets...
2018-09-18 19:21:15,829:INFO: Validation dataset...
2018-09-18 19:21:20,480:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:21:20,481:INFO: Training dataset...
2018-09-18 19:21:21,940:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:21:21,940:INFO: Done
2018-09-18 19:21:21,940:INFO: Setup time: 0h0m7.10s
2018-09-18 19:21:21,941:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:21:21,941:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:21:21,941:INFO: Starting training for 1 epoch(s)
2018-09-18 19:21:21,941:INFO: Pretraining evaluation...
2018-09-18 19:21:21,941:INFO: Validation on val set
2018-09-18 19:21:24,557:INFO: Saving embeddings for summary 0
2018-09-18 19:21:25,804:INFO: Saving embeddings for summary 1
2018-09-18 19:21:27,182:INFO: Saving embeddings for summary 2
2018-09-18 19:21:28,334:INFO: === User interrupted execution ===
2018-09-18 19:22:09,374:INFO: ----Starting train script in mode: train----
2018-09-18 19:22:09,374:INFO: Loading datasets...
2018-09-18 19:22:10,386:INFO: Validation dataset...
2018-09-18 19:22:14,453:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:22:14,453:INFO: Training dataset...
2018-09-18 19:22:15,752:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:22:15,753:INFO: Done
2018-09-18 19:22:15,753:INFO: Setup time: 0h0m6.38s
2018-09-18 19:22:15,753:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:22:15,753:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:22:15,753:INFO: Starting training for 1 epoch(s)
2018-09-18 19:22:15,753:INFO: Pretraining evaluation...
2018-09-18 19:22:15,753:INFO: Validation on val set
2018-09-18 19:22:18,365:INFO: Saving embeddings for summary 0
2018-09-18 19:22:19,633:INFO: Saving embeddings for summary 1
2018-09-18 19:22:20,996:INFO: Saving embeddings for summary 2
2018-09-18 19:22:22,331:INFO: Saving embeddings for summary 3
2018-09-18 19:22:23,693:INFO: Saving embeddings for summary 4
2018-09-18 19:22:24,806:INFO: === User interrupted execution ===
2018-09-18 19:24:03,576:INFO: ----Starting train script in mode: train----
2018-09-18 19:24:03,576:INFO: Loading datasets...
2018-09-18 19:24:04,575:INFO: Validation dataset...
2018-09-18 19:24:09,221:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:24:09,221:INFO: Training dataset...
2018-09-18 19:24:10,949:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:24:10,949:INFO: Done
2018-09-18 19:24:10,949:INFO: Setup time: 0h0m7.37s
2018-09-18 19:24:10,950:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:24:10,950:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:24:10,950:INFO: Starting training for 1 epoch(s)
2018-09-18 19:24:10,950:INFO: Pretraining evaluation...
2018-09-18 19:24:10,951:INFO: Validation on val set
2018-09-18 19:24:13,514:INFO: Saving embeddings for summary 0
2018-09-18 19:24:14,780:INFO: Saving embeddings for summary 1
2018-09-18 19:24:16,149:INFO: Saving embeddings for summary 2
2018-09-18 19:24:17,447:INFO: Saving embeddings for summary 3
2018-09-18 19:24:18,787:INFO: Saving embeddings for summary 4
2018-09-18 19:24:33,704:INFO: - Eval metrics : AUC: 0.110 ; center_error: 82.673 ; loss: 1.324
2018-09-18 19:24:33,705:INFO: Epoch 1/1
2018-09-18 19:24:33,705:INFO: Training on train set
2018-09-18 19:24:35,416:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 193, in main
    args, summ_maker=summ_maker)
  File "train.py", line 281, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 358, in train
    loss.backward()
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/tensor.py", line 96, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA error: out of memory
2018-09-18 19:24:35,419:INFO: === Execution Terminated with error ===
2018-09-18 19:26:44,468:INFO: ----Starting train script in mode: train----
2018-09-18 19:26:44,469:INFO: Loading datasets...
2018-09-18 19:26:45,474:INFO: Validation dataset...
2018-09-18 19:26:50,857:INFO: The user set eval_epoch_size (10000) is bigger than the size of the eval set (92). 
 Setting eval_epoch_size to the eval set size.
2018-09-18 19:26:50,858:INFO: Training dataset...
2018-09-18 19:26:53,214:INFO: The user set train_epoch_size (10000) is bigger than the size of the train set (76). 
 Setting train_epoch_size to the train set size.
2018-09-18 19:26:53,215:INFO: Done
2018-09-18 19:26:53,215:INFO: Setup time: 0h0m8.75s
2018-09-18 19:26:53,215:INFO: Using Exponential Learning Rate Decay of 1
2018-09-18 19:26:53,216:INFO: Epoch sizes: 76 in train and 92 in eval
2018-09-18 19:26:53,216:INFO: Starting training for 1 epoch(s)
2018-09-18 19:26:53,216:INFO: Pretraining evaluation...
2018-09-18 19:26:53,217:INFO: Validation on val set
2018-09-18 19:26:55,857:INFO: Saving embeddings for summary 0
2018-09-18 19:26:57,130:INFO: Saving embeddings for summary 1
2018-09-18 19:26:58,476:INFO: Saving embeddings for summary 2
2018-09-18 19:26:59,806:INFO: Saving embeddings for summary 3
2018-09-18 19:27:01,124:INFO: Saving embeddings for summary 4
2018-09-18 19:27:16,027:INFO: - Eval metrics : AUC: 0.170 ; center_error: 87.234 ; loss: 1.045
2018-09-18 19:27:16,027:INFO: Epoch 1/1
2018-09-18 19:27:16,028:INFO: Training on train set
2018-09-18 19:27:17,708:ERROR: Fatal error in main loop
Traceback (most recent call last):
  File "train.py", line 193, in main
    args, summ_maker=summ_maker)
  File "train.py", line 281, in train_and_evaluate
    summ_maker=summ_maker)
  File "train.py", line 358, in train
    loss.backward()
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/tensor.py", line 96, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/cpinard/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA error: out of memory
2018-09-18 19:27:17,709:INFO: === Execution Terminated with error ===
